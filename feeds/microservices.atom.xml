<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Starting Point - Microservices</title><link href="https://www.nacnez.com/" rel="alternate"></link><link href="https://www.nacnez.com/feeds/microservices.atom.xml" rel="self"></link><id>https://www.nacnez.com/</id><updated>2022-07-30T00:00:00+05:30</updated><entry><title>The Right size of a µService?</title><link href="https://www.nacnez.com/micro-service-size.html" rel="alternate"></link><published>2022-07-30T00:00:00+05:30</published><updated>2022-07-30T00:00:00+05:30</updated><author><name>Srinivas Narayanan</name></author><id>tag:www.nacnez.com,2022-07-30:/micro-service-size.html</id><summary type="html">&lt;p&gt;Ideas to figure out if your microservice is too big or too small.&lt;/p&gt;</summary><content type="html">
&lt;div class="admonition tip"&gt;
&lt;p class="admonition-title"&gt;TL;DR&lt;p&gt;There is no simple formula to figure out the right size of a microservice. There are different considerations, which affect size in different ways. This is illustrated in Fig 4 and 5. These figures provide you a bird's eye view on the considerations you have to keep in mind.&lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Origin Note&lt;p&gt;I had given a session to my engineering team at &lt;a href="https://getsimpl.com/about-us/"&gt;Simpl&lt;/a&gt; on this topic as part of our Bi-Weekly Tech talks. Decided to create a blog post out of it since I (and others) can refer to it later.  &lt;/p&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I have been working with microservices for some time. There is one question that keeps coming back when I work with them or discuss them with people. How small or big a microservice needs to be? The below blog post is my attempt to explain (&amp;amp; understand) the concepts around this &amp;amp; express my opinions/inferences along with it.&lt;/p&gt;
&lt;p&gt;At the outset, I need to establish some context about microservices. A very short journey into history &amp;amp; a foray into the realm of definitions will help us understand the core topic better.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="before-microservices-there-was"&gt;&lt;span class="bold-green"&gt;Before microservices there was...&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Microservices have been around for some time now, but they are relatively nascent compared to these older fellows which I am going to describe now.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;At the beginning of time there was Client Server architecture!&lt;/em&gt; Ok, that is not the truth, I have only gone back a few decades here. There were other architecture styles before, but they are not relevant to our conversation. Also, I am not explaining the entire computing history. The two relevant architecture styles are listed below:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;N-tier architecture (client/server?) &lt;/li&gt;
&lt;li&gt;Service Oriented architecture&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let us dig a little deeper.&lt;/p&gt;
&lt;h3 id="n-tier-architecture"&gt;&lt;span class="bold-calm"&gt;N-tier Architecture&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;This architecture started off as the basic client server architecture which is two tiers. It was just a thick client which talked to a server typically for data storage. This obviously had some problems &amp;amp; hence things evolved. Cutting things short, we get to the final (or at least prevalent) incarnation of this architecture: the 3 tier architecture. &lt;/p&gt;
&lt;p&gt;The tiers in a 3 tier architecture are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A thin client, like the browser&lt;/li&gt;
&lt;li&gt;A thick middle tier server component, which held all the business logic&lt;/li&gt;
&lt;li&gt;A data store, which held all the data.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="figure"&gt;
&lt;img alt="N tier architecture" src="https://www.nacnez.com/images/ms_size/n_tier_architecture.png"/&gt;
&lt;p class="caption"&gt;Fig 1: N(3) Tier Architecture&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I am sure this is familiar to all of you as it is a valid architecture style even today. Monoliths were/are basically 3 tier applications in all their pomp &amp;amp; glory (and extra cheese!). Actually, many of the microservices today follow the same architecture.&lt;/p&gt;
&lt;p&gt;The 3 tier architecture was embraced wholeheartedly by the software community. Advanced middle tier components called application servers got built with tonnes of features, to make it easy for developers to deploy 3 tier applications. This lead to creation of highly capable applications which can deliver a lot of useful functionality to multiple thin clients. &lt;/p&gt;
&lt;p&gt;Lo &amp;amp; Behold! The &lt;span class="bold-angry"&gt;Monolith&lt;/span&gt; was born!&lt;/p&gt;
&lt;h3 id="service-oriented-architecture"&gt;&lt;span class="bold-calm"&gt;Service Oriented Architecture&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;I think this architecture's inception happened like this (purely a figment of my imagination) :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software people always want to reuse code &amp;amp; leverage functionality in other existing applications without having to change them much (so use them remotely).&lt;/li&gt;
&lt;li&gt;Software people always like to componentize things.&lt;/li&gt;
&lt;li&gt;These folks come across XML &amp;amp; figured out that this language can be used to represent any piece of data &amp;amp; can be read by any tech (&lt;span class="small-italicized-green"&gt;Side note: there was a platform war going on at that time in tech history just like now there is cloud war going on&lt;/span&gt;).&lt;/li&gt;
&lt;li&gt;Then they put all these together &amp;amp; SOA was born. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am just making this up and hence will be missing a lot of details (the individual aspects mentioned here are true but the story itself is fictional). &lt;/p&gt;
&lt;p&gt;One key thing I did not specify yet are the &lt;span class="bold-calm"&gt;Service Design principles&lt;/span&gt; which are very important (according to me). So let us focus on them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standard contract &amp;amp; Service abstraction&lt;/li&gt;
&lt;li&gt;Service autonomy (implementation &amp;amp; location)&lt;/li&gt;
&lt;li&gt;Service discoverability&lt;/li&gt;
&lt;li&gt;Service statelessness&lt;/li&gt;
&lt;li&gt;Service composability&lt;/li&gt;
&lt;li&gt;Service reusability&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you look at these principles, they all make sense even today. Don't they? I would even wager that they make even more sense today. Especially in the context of microservices.&lt;/p&gt;
&lt;hr class="style-three"&gt;
&lt;div class="figure align-right"&gt;
&lt;img alt="Service Oriented Architecture" src="https://www.nacnez.com/images/ms_size/soa.jpeg"/&gt;
&lt;p class="caption"&gt;Fig 2: Service Oriented Architecture&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;While the SOA principles were (/are) very strong, the real world implementations got ugly soon. Given the enterprise focus of SOA, things changed for the worse. Enterprises already had a lot of software applications lying around &amp;amp; working in silos. Software Vendors took the SOA's promise of reusability &amp;amp; interoperability &amp;amp; created all sorts of products (read ESB &lt;span class="emoji"&gt;😖&lt;/span&gt;) which were supposed to help these enterprises to leverage these siloed apps. This did not go as planned since such a transformation requires a lot of fundamental change in how these enterprises work, which mere tools can't make happen. Enterprises made a lot of upfront investment on these vendor products expecting them to do some kind of magic. Of course, they did not get much out of it in the timeline they wanted it on. Not only that, these products became single point of failures (both from a dev &amp;amp; runtime perspective).&lt;/p&gt;
&lt;p&gt;Apart from the above progression, there was one more issue. To solve a wide range of problems in these products &amp;amp; in general within SOA, many standards were evolved (WS*). While this effort was admirable, it did not sit well with developers since it meant a lot of complex artifacts added, which felt like boilerplate since they did not add visible value.&lt;/p&gt;
&lt;p&gt;All said and done, I don't think SOA is dead. It has just morphed to what is called &lt;span class="bold-green"&gt;microservices&lt;/span&gt; now (my opinion).&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="why-microservices-instead-of-monolith"&gt;&lt;span class="bold-green"&gt;Why microservices (instead of monolith)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;I am not going to explain the microservice architecture since in today's world everyone has a pretty good idea about it. Instead, I am going to explore the reasons why microservices are preferred over monoliths. I get into this, because these attributes come into play when we eventually want to figure out the right size of a microservice. Remember when a microservice gets too big, it becomes a monolith. (&lt;span class="small-italicized-green"&gt;When it gets too small then it becomes a nano/pico service&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;There are some well known reasons for preferring microservices:&lt;/p&gt;
&lt;h3 id="1-independent-deployment"&gt;&lt;span class="bold-calm"&gt;1. Independent Deployment&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Microservices are fantastic because they allow for independent deployment of specific changes. When a feature requires localized changes on a particular module (or code path), a microservice (which represents that module) will allow us to deploy that part alone (by deploying the microservice) instead of deploying the entire functionality (app) which is required in case of a monolith. This plays out in many business scenarios. &lt;/p&gt;
&lt;p&gt;This is a pretty crucial aspect of a microservice. If this is not realized then the point of having microservices is lost.&lt;/p&gt;
&lt;h3 id="2-freedom-of-tech-choices"&gt;&lt;span class="bold-calm"&gt;2. Freedom of tech choices&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Given that microservices focus on a smaller cohesive footprint, they allow for more flexibility in tech choices. As they say, you can use the right tool for the job!&lt;/p&gt;
&lt;h3 id="3-easy-replaceability"&gt;&lt;span class="bold-calm"&gt;3. Easy replaceability&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The ability to take a microservice out &amp;amp; replace it with a new one, in a relatively short amount of time, is cool. This is of course not possible with a monolith. This is another key aspect of a microservice. It allows us product developers to make mistakes &amp;amp; correct them.&lt;/p&gt;
&lt;p&gt;Having said that, in the real world, we forget this &amp;amp; expect that everything works perfectly, the first time. Rewriting or replacing is always considered as an unacceptable thing. This defeats one of the great benefits of microservices - the ability to make a mistake &amp;amp; learn from it. &lt;/p&gt;
&lt;h3 id="4-shorter-time-to-market"&gt;&lt;span class="bold-calm"&gt;4. Shorter time to market&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Microservices allow for a focused approach. Whenever the business wants to create a new feature, the focus of the corresponding team &amp;amp; its microservice(s) allows them to independently build out the feature &amp;amp; release it. This means that we are faster to market.&lt;/p&gt;
&lt;h3 id="5-independent-scaling"&gt;&lt;span class="bold-calm"&gt;5. Independent scaling&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;In my experience, this is the favorite reason people think about &amp;amp; give others, when wanting to create microservices. Scaling is a problem everybody wants to have &amp;amp; solve. The microservice architecture's capability of making this happen is the most important reason for everyone to flock to this architecture style. &lt;/p&gt;
&lt;p&gt;Many times this solution leads people down the path of very small services (nano/pico services) which may not really solve the actual scalability problem. That said, no one can refute that microservice architecture when applied correctly can provide you ways to independently scale different parts of the bigger system, and that, is surely an advantage.&lt;/p&gt;
&lt;hr class="style-three"&gt;
&lt;p&gt;Now that the obvious ones are done, there are some advantages of microservices which are important but not appreciated as much:&lt;/p&gt;
&lt;h3 id="1-organized-around-business-capabilities"&gt;&lt;span class="bold-calm"&gt;1. Organized around Business Capabilities&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The premise of a microservice is that it is organized around business capabilities. For example, you might create a microservice for payment management (&lt;em&gt;'Payments'&lt;/em&gt;) &amp;amp; another for order management (&lt;em&gt;'Orders'&lt;/em&gt;). Each of these are distinct business capabilities and have different concerns, interactions &amp;amp; business focus. This type of organization leads microservices to evolve independently based on what a particular business team (domain experts) wants to do in that specific area.&lt;/p&gt;
&lt;p&gt;For example, if we want to use a different payment gateway because it provides better success rates, it is the &lt;em&gt;'Payments'&lt;/em&gt; microservice which will work &amp;amp; evolve this feature. The &lt;em&gt;'Orders'&lt;/em&gt; microservice does not bother about this.&lt;/p&gt;
&lt;p&gt;Also, by doing this there is easier alignment of engineering teams with business goals, and it helps the team to build domain specific knowledge, which can help in making quicker &amp;amp; better decisions during development.&lt;/p&gt;
&lt;p&gt;Some earlier mentioned benefits like &lt;em&gt;shorter time to market&lt;/em&gt;, &lt;em&gt;independent deployment&lt;/em&gt; etc. work because of this aspect of microservices.&lt;/p&gt;
&lt;h3 id="2-strong-interfaces"&gt;&lt;span class="bold-calm"&gt;2. Strong Interfaces&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Once you go down the path of microservices, we would have split a large app into smaller services. The interactions between them need to happen remotely through an interface. This interface has to be clearly defined, is generally coarse grained, and all interactions happen only through it. &lt;/p&gt;
&lt;p&gt;While we don't want too many such interactions happening for fulfilling a single user action, when these calls do happen, they happen in a well-defined &amp;amp; clear manner. This reduces coupling between systems. Also, with proper microservices we reduce the creeping up of multiple concepts within a single service which removes cognitive overload. &lt;/p&gt;
&lt;p&gt;In summary, two different microservices or sub-systems always talk to each other through strong well-defined interfaces. This leads to a lot of good things in the life of developers of both systems.&lt;/p&gt;
&lt;h3 id="3-decentralized-governance"&gt;&lt;span class="bold-calm"&gt;3. Decentralized governance&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;We already covered the fact that there is freedom of choice in terms of technologies used when we use microservices. That is part of governance, but that is not all of it. With microservices, individual microservice teams can even choose different processes &amp;amp; tools to run their development. &lt;/p&gt;
&lt;p&gt;While, there needs to be a set of guidelines &amp;amp; some basic oversight to ensure that &lt;em&gt;the fruit does not fall too far away from the tree&lt;/em&gt;, the need to govern everything through &lt;span class="bold-angry"&gt;&lt;strong&gt;committee&lt;/strong&gt;&lt;/span&gt; is reduced. This means that the dimensions of freedom for teams are much higher, leading to a more agile engineering organization.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="what-does-micro-mean"&gt;&lt;span class="bold-green"&gt;What does “micro” mean?&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Now that we have covered why microservices, let us move back towards the question of this write-up. What does "micro" mean in a microservice? What is the right size of a microservice? &lt;/p&gt;
&lt;p&gt;The rest of the blog post is about answering that in detail. But to start off, I thought that I could briefly cover some points which people say about size of microservices. I am mentioning the extreme ones here because that has been my experience. More reasonable ideas on the right size of microservices will be presented down the line.&lt;/p&gt;
&lt;h3 id="200-lines-of-code"&gt;&lt;span class="bold-calm"&gt;200 Lines of Code &lt;span class="emoji"&gt;😖&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;One of the metrics people use to talk about microservice size is lines of code. There are claims that microservices should be only 200 lines. There are others who say it can be 500 or 1000 lines. These absolute values don't make sense to me, because lines of code can vary a lot depending on the language platform &amp;amp; the frameworks used in development. If I am building something using say, the RoR stack, a few lines of code would be enough to create a complete CRUD app. If I use direct Golang or C to build the same app the line of code required might be order of magnitude higher. So defining microservice size using lines of code count does not make sense to me.&lt;/p&gt;
&lt;h3 id="a-person-per-service"&gt;&lt;span class="bold-calm"&gt;A person per service &lt;span class="emoji"&gt;😕&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Another famous one I have heard about the right size of a microservice is that it can be managed by a single person for the most part. This again does not make a lot of sense to me. Microservices are supposed to represent business functions. Typically, in any normal business function (unless you are very small startup), the processes followed are involved &amp;amp; are typically managed by multiple people. One developer catering to all these needs does not sound feasible to me.    &lt;/p&gt;
&lt;h3 id="an-endpoint-per-service"&gt;&lt;span class="bold-calm"&gt;An endpoint per service &lt;span class="emoji"&gt;😩&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The third kind of logic I have heard is to split things up in such a way that a service only serves one endpoint. The argument is that one can scale this independently &amp;amp; hence it gives us a lot of advantage. &lt;/p&gt;
&lt;p&gt;For me this setup does not make sense most of the time. If there is a business domain that only serves one API endpoint, I would be very surprised. There are potential niche domains for which this might happen. Even so, one API endpoint is cutting it too small. In my experience, I have never seen such a domain &amp;amp; I would love to hear from others if such domains exist. &lt;/p&gt;
&lt;p&gt;There are other ideas of splitting the same domain into multiple services (since the domain needs more than one endpoint). This is a valid idea but when I probe deeper with these advocates, I find them expressing the idea of sharing a data store (database) across all these services. Once that happens, I find it difficult to stay with them. Sharing a data store breaks one of the fundamental principles of microservices - autonomy. That is not acceptable to me. So I walk away from the idea.&lt;/p&gt;
&lt;hr class="style-three"&gt;
&lt;p&gt;None of these ideas on the right size of microservices are good according to me (making it explicit in case my subtle hints were not clear enough), though I have heard them often. Now I will start describing some better ideas to figure out the right size of a microservice. But before I do that (&lt;span class="small-italicized-green"&gt; not again! &lt;/span&gt;), I want to take an important digression. This digression is about Domain driven design, and to me, it is one of the vital ideas in the area of microservices.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="domain-driven-design"&gt;&lt;span class="bold-green"&gt;Domain driven design&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Domain driven design is a methodology or approach of developing software that focuses on a creating a software based model of the actual domain it is representing, thereby making the software model rich in concepts, processes &amp;amp; rules of the domain. It all started with &lt;a href="https://www.amazon.in/gp/product/B00794TAUG"&gt;a book created by Eric Evans&lt;/a&gt;. &lt;/p&gt;
&lt;div class="figure align-right"&gt;
&lt;img alt="Domain Driven Design by Eric Evans: Model Integrity Patterns" src="https://www.nacnez.com/images/ms_size/ddd.png"/&gt;
&lt;p class="caption"&gt;Fig 3: Domain Driven Design by Eric Evans: Model Integrity Patterns&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This book focused on a bunch of concepts which I will describe very briefly in this write-up. I am touching this area of study because I think it is relevant to our topic - microservice &amp;amp; it's right size. A detailed description is just not possible in this post. Given that more than one books have been written on the topic, there are multiple articles, courses etc. (and also communities), I will ask you to dive into one (or more) of them. &lt;span class="small-italicized-green"&gt; May be down the line I will attempt to write something about it &lt;/span&gt;. Let us move to the crash course on the subject:&lt;/p&gt;
&lt;h3 id="bounded-contexts"&gt;&lt;span class="bold-calm"&gt;Bounded Contexts&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;One of the key ideas in domain driven design (DDD) is to organize large systems according to their business domains. As soon as I say this, I am sure you would realize that this is fantastic in the context of microservices. Microservices are also organized around business capabilities, so this seems like a good match to start with.&lt;/p&gt;
&lt;p&gt;Within the context of a business area, we can define a domain model that makes sense within that context. Outside that context these domain concepts generally don't make clear sense. Or at least they make different sense in different contexts. This boundary is defined as a "Bounded Context" &amp;amp; it is focused on a single domain. If you think a little, this idea is the foundation of microservices. A bounded context can be built using one or more microservices.&lt;/p&gt;
&lt;h3 id="ubiquitous-language"&gt;&lt;span class="bold-calm"&gt;Ubiquitous Language&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The next important concept of DDD is called the Ubiquitous Language. As the name suggests this means a language that is used across teams and disciplines - ubiquitous. It is a common language for developers &amp;amp; domain experts and is used to express business concepts &amp;amp; rules of the domain. The same language is also used to express concepts/rules in the software domain model. Let me reiterate: The idea is that software uses the terminology present in the business domain &amp;amp; makes it easy for business experts to understand the software as well.&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; This one does not contribute too much to the microservice architecture discussion, but I mentioned here because it is of fundamental importance in DDD. &lt;/span&gt;&lt;/p&gt;
&lt;h3 id="context-maps"&gt;&lt;span class="bold-calm"&gt;Context maps&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Any given business organization or super system is made up of multiple bounded contexts. There needs to be a way to describe how interactions between different bounded contexts happen. In the context of DDD, this interaction is expressed as Context maps. Context maps are very powerful to understand the business systems. It can also be very handy in figuring out our microservices. A context map could help us understand how our microservices work together, how they interact, their communication patterns, build and runtime dependencies etc.&lt;/p&gt;
&lt;h3 id="aggregates"&gt;&lt;span class="bold-calm"&gt;Aggregates&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;There is one more important idea in DDD that I need to discuss here: &lt;span class="bold-green"&gt;"Aggregate"&lt;/span&gt;. This is one of the tactical design patterns presented in the DDD book. An aggregate represents a composite domain object which can contain one or more "entities" or "value objects" &lt;span class="small-italicized-green"&gt;(these are other tactical patterns in DDD which I won't cover)&lt;/span&gt; &amp;amp; ensures that invariants across these composed objects are kept intact. It also represents a consistency boundary. &lt;/p&gt;
&lt;p&gt;An example could be an &lt;em&gt;'Order'&lt;/em&gt; &amp;amp; its &lt;em&gt;'LineItems'&lt;/em&gt;. One of the rules/invariants could be the value of the order should be equal to sum of the values of its line items. &lt;/p&gt;
&lt;hr class="style-three"&gt;
&lt;p&gt;These are some key ideas of DDD &amp;amp; I have described them only as much as I require for explaining how they affect microservices &amp;amp; their size. There is a lot more to dig deeper in this area &amp;amp; I will provide references for the same, later in this write-up.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="what-is-the-right-microservice-size-considerations"&gt;&lt;span class="bold-green"&gt;What is the right microservice size? - Considerations&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Now that we are done with all the ceremony, we can get into the main discussion. Though I call it ceremony, I think the previous sections are relevant &amp;amp; will make this section much simpler to explain &amp;amp; understand. The following are the ideas, which we have to keep in mind when we think about the size of a microservice - how micro is micro?&lt;/p&gt;
&lt;h3 id="bounded-contexts_1"&gt;&lt;span class="bold-calm"&gt;Bounded Contexts&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;I covered bounded contexts in the earlier section. As I mentioned there, a microservice can contain a maximum of one bounded context. A bounded context represents a business domain &amp;amp; hence having a microservice representing more than one business domain defeats the main purpose of microservices - independence &amp;amp; autonomy. If two bounded contexts are present within a single microservice and one business team focused on a particular context wants changes on their aspects, then that will need to be synced with the needs of the other team &amp;amp; their bounded context. While keeping separate microservices does not guarantee that different business teams can work independently all the time, it takes it towards the best possible outcome.   &lt;/p&gt;
&lt;h3 id="transaction-boundaries-consistency"&gt;&lt;span class="bold-calm"&gt;Transaction Boundaries &amp;amp; Consistency&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;While the bounded context acts as a force on the upper bound of size for a microservice, the need to ensure that transactions work properly &amp;amp; data consistency is maintained in a given use case acts as a force on the lower bound.&lt;/p&gt;
&lt;p&gt;There was a time when Java EE world thought they solved distributed transactions with 2 phase commit &amp;amp; everyone should be happy. But everyone was not happy. Scalability challenges &amp;amp; complexity of the architecture did not help the cause. Also, the solution of platform specific and everyone did not want to move to the Java EE stack for their own valid reasons.&lt;/p&gt;
&lt;p&gt;As of today distributed transactions are not a solved problem at a tech level (there are patterns like Saga which help, but they add to the complexity). So if we want a user interaction to be properly managed as a transaction &amp;amp; consistency to be maintained for the data, then that interaction must not span microservices. It should begin &amp;amp; end within one microservice. If that does not happen then data consistency &amp;amp; good user experience cannot be guaranteed. &lt;em&gt;Somehow in today's world these things have become important!&lt;/em&gt; So this is a criterion to keep in mind to keep the service big enough.&lt;/p&gt;
&lt;p&gt;The concept of an aggregate plays well in this aspect. Since an aggregate is a consistency boundary, a microservice that contains at least one entire aggregate and no partial aggregates, can meet this criterion. If an aggregate is split up into two microservices then it can cause havoc. So aggregate size acts as a lower bound to the size of a microservice.&lt;/p&gt;
&lt;h3 id="infrastructure-aspects"&gt;&lt;span class="bold-calm"&gt;Infrastructure Aspects&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;A new microservice typically needs a set of infrastructure components. There are the basic compute, memory &amp;amp; network needs and things generally don't stop there. Most of these microservices will need other elements like databases &amp;amp; caches, and those need to be considered as part of infrastructure needs. And it does not stop here. &lt;/p&gt;
&lt;p&gt;        If you are going to develop &amp;amp; run a microservice, then a team needs to work on it. It needs to build, test &amp;amp; work with it. This means more infra needed for various environments like development, staging, testing etc. Keeping this in mind, creation of tiny microservices means adding to overhead in terms of infra needs. Our IT or Devops team may not be happy about it.&lt;/p&gt;
&lt;p&gt;Having said all this, the current cloud based world (with spot instances &amp;amp; server-less infrastructure) makes this somewhat easier to manage or handle. But I still think it involves significant work &amp;amp; hence cannot be treated as a non-reason when it comes to creating microservices &amp;amp; their corresponding &lt;em&gt;small&lt;/em&gt; size. &lt;/p&gt;
&lt;p&gt;So before you think that I will split up the service to make it smaller keep the infra requirement in mind. &lt;/p&gt;
&lt;h3 id="iteration-speed-agility"&gt;&lt;span class="bold-calm"&gt;Iteration speed &amp;amp; Agility&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;One of the key purposes of creating microservices in an organization is to be able to improve its agility &amp;amp; iteration speed. An ideal microservice, which focuses on a specific business function, allows that function to quickly add new changes that can be shipped to customers to get quick feedback. This ability to ship a product/feature &amp;amp; get quick feedback is the hallmark of agility. This increased iteration speed is what allows organizations to keep ahead of their competition. The microservice architecture's key benefit is to allow this to happen.&lt;/p&gt;
&lt;p&gt;In terms of &lt;em&gt;'right-sizing'&lt;/em&gt; the microservice, this is another guiding principle. If the microservice size still allows our team to deliver in an agile manner then we are safe with its size. If it is slowing things down then it is potentially time to look at making changes to the size of the service (either split them or combine them). This consideration is slightly indirect but if we track our agile processes properly then this can be an eye-opener to determine microservice size. &lt;/p&gt;
&lt;p&gt;Couple of opposing forces to note in this context:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Typically, when services grow big, testing all the scenarios takes more time. So &lt;span class="bold-green"&gt;testing time&lt;/span&gt; increases with the size and hence it pushes services down to make them smaller.&lt;/li&gt;
&lt;li&gt;If a feature change needs developers to work with multiple services (within the same team) to release it, then overall &lt;span class="bold-green"&gt;development time&lt;/span&gt; increases. Developers have to work with all the services individually, test against their contracts (with &amp;amp; without mocks/stubs), deploy in different environments in a co-ordinated manner and also ensure distributed communication scenarios are handled. So if we want &lt;em&gt;development time&lt;/em&gt; to be reduced within a context of business team it might be better to have a bigger service that caters to that business function fully.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="team-size-two-pizzas-team"&gt;&lt;span class="bold-calm"&gt;Team Size (Two Pizzas team)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;This criterion speaks a lot to engineering managers. Every manager wants to have a clear idea on the right (or good) team size for managing a microservice. The accepted intelligence out there is that a microservice team has as many members as can be fed by &lt;strong&gt;"two pizzas"&lt;/strong&gt;. This means a size of around 6 - 10 members (few indicate that it can be up to 12 members). &lt;span class="small-italicized-green"&gt;The original quote of "Pizza teams" came from Jeff Bezos.&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;From an agile team perspective, who constitutes a team? Is it the set of developers in the team? What about testers? What about engineering managers &amp;amp; product owners? In the literature out there, this aspect is not clear. So I am going to wing this part, based on my experience &amp;amp; intuition. &lt;/p&gt;
&lt;p&gt;For me, an agile team which takes care of a business focus area or a domain should be the set of people who interact &amp;amp; communicate about it on a daily basis. Developers, testers &amp;amp; product owner(s), all form part of that team. Developers are focused in creating the feature, the testers are focused on ensuring quality of the feature &amp;amp; the product owner is the one responsible for envisioning the feature (&lt;span class="small-italicized-green"&gt;I say 'responsible' to differentiate the fact that she does not have to be the only person doing the thinking, but she takes charge of the process&lt;/span&gt;). These members focus on the service/business area day in &amp;amp; day out. Another important criteria of an agile team is that they are self-managed. &lt;/p&gt;
&lt;p&gt;         If these two criteria are met, then those are the team members that manage the bounded context &amp;amp; they can be as big as 6 - 10 members. Let me summarize the types of people in the team so far (they are just in alphabetical order):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Developers&lt;/li&gt;
&lt;li&gt;Product Owner(s)&lt;/li&gt;
&lt;li&gt;Testers&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;     You might ask: What about the engineering manager? If the engineering manager is solely focused on the team &amp;amp; contributing to the teams work on a regular basis then they could also be considered in the 10 member gang. But if they have a broader focus &amp;amp; are indirectly involved with the team and engage at higher level, then I would consider them to be sitting outside the 10 member team. Similar approach can be applied to members from Devops, Security etc.&lt;/p&gt;
&lt;p&gt;Back to the microservice size question. This agile team is focused on a bounded context/domain &amp;amp; hence need to manage one or more services within itself. It is ok for the team to manage just one service which takes care of all of business functions. Or the team might decide that it needs to manage it using 2 - 4 services. Either way, things work. &lt;/p&gt;
&lt;p&gt;What does NOT work is this: For managing this domain specific service, if we start needing a team bigger than 10 people, then it may be time to split things up. This splitting up is not just about the service. If I need a team bigger than 10 people to manage a business subdomain then it means that the domain is more nuanced and/or broad. So the business needs to look at how to split the business function up to provide better focus on each of these parts. This part is purely my own opinion &amp;amp; hence subject to disagreement. I am ok with that. &lt;/p&gt;
&lt;p&gt;The one thing we should not forget from this section is that team size acts as an upper limit determinant of microservice size and pushes it down.&lt;/p&gt;
&lt;h3 id="modularization"&gt;&lt;span class="bold-calm"&gt;Modularization&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;The concept of modularization is well known to a lot of us. We want modularization because it helps us to understand things easily &amp;amp; reuse things. Also, modules operate with each other through contracts, and contracts are always a good thing. Creating small modules to make a big system is not a new idea. It has been around for long. &lt;/p&gt;
&lt;p&gt;Microservices take this to the next level where they are &lt;span class="bold-calm"&gt;reusable deployed modules&lt;/span&gt; which can be used by others through &lt;em&gt;an API contract&lt;/em&gt;. When a developer is working within a module, she doesn't have to keep in mind a lot of other (external) concepts but can focus on only the ones that make sense in the given context. &lt;/p&gt;
&lt;p&gt;When people use normal modules (that are not microservices) in an application, they tend to be less disciplined in their usage of other module code. They just import it anywhere they want &amp;amp; start using it as they like. This increases the coupling between modules. Microservices stop this kind of undisciplined usage since calling a microservice is a network call (&lt;span class="small-italicized-green"&gt;there are associated costs&lt;/span&gt;) &amp;amp; it is generally done through a very strict contract (interactions typically happen using a specific pattern - client). This means that developers will adhere to module boundaries, and will be deliberate about module usage.&lt;/p&gt;
&lt;p&gt;From a size perspective, small modules are always good. So as per modularization, small microservices are also good. That said modules need to be cohesive things which expose a single responsibility (or a single set of them). That applies to microservices too &amp;amp; if you can find the smallest cohesive set of functionality then we can make it into a microservice. In summary, modularization tend to make services smaller and push on upper bound to make things smaller.&lt;/p&gt;
&lt;p&gt;The story does not stop here. Let us continue to the next one. &lt;/p&gt;
&lt;h3 id="refactorability"&gt;&lt;span class="bold-calm"&gt;Refactorability&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Refactorability as a term feels odd from an English perspective, but makes some sense from a perspective of developer. The way I understand it is that, it refers to the ability of a codebase to lend itself to easy refactoring. This ability depends on a lot of things. Generally good IDEs &amp;amp; editors provide this ability &amp;amp; they generally work better in the case of statically typed languages. &lt;/p&gt;
&lt;p&gt;As a developer, refactoring code within a project, to create some clean &amp;amp; readable code has been one of the best joys I have experienced in my career. It rivals &lt;span class="small-italicized-green"&gt;(even beats it sometimes)&lt;/span&gt; the feeling of building something completely from scratch. &lt;/p&gt;
&lt;p&gt;Now back to the process of refactoring. Irrespective of the development platform, most of the IDEs allow you to refactor code within a project. They generally don't allow you to refactor code across multiple projects. This is even more true in case these multiple projects refer to different microservices which are integrating over a structured contract made up of say JSON and are potentially implemented in different platforms.   &lt;/p&gt;
&lt;p&gt;While from a modularity standpoint, creating smaller &amp;amp; focused microservices is a good thing, when you do that, you tend to lose out the ability to easily refactor code. This again increases &lt;span class="bold-green"&gt;development time&lt;/span&gt; and hence something to consider. &lt;/p&gt;
&lt;p&gt;So don't make microservices so small that refactoring is very difficult. This generally won't be problem if the concerns of microservices are quite separate (then they won't have much commonality to refactor). To sum up, modularization is great, but it needs to be balanced with refactorability.&lt;/p&gt;
&lt;h3 id="scaling"&gt;&lt;span class="bold-calm"&gt;Scaling&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;One of the key reasons for creating microservices is the ability to independently scale small services as per their needs. Please take special note of the word &lt;span class="bold-calm"&gt;independently&lt;/span&gt; in that sentence. When we say we can 'independently' scale, it should not just be a theoretical possibility. Creating small microservices that can scale separately since they deal with independent business use cases, is a good idea. But if that is not the case then there is a problem. &lt;/p&gt;
&lt;p&gt;Let us take a counter example: &lt;/p&gt;
&lt;p&gt;Let us say that a single business use case (which might include multiple user interactions) is spanning three services. Also, let us say that these services primarily serve this business use case only. So when you want to scale to serve more users of the business case concurrently, you will have to scale all the three services involved in a corresponding &amp;amp; related manner. This is really &lt;em&gt;NOT independence of scaling&lt;/em&gt;. What this is, is a case where you don't have any true independent scaling, but you have incurred all the cost of having a distributed system. &lt;/p&gt;
&lt;p&gt;     We need to keep this in mind before we decide to split things up to small services. So, while the idea of independent scaling will push the size of the service to be smaller, please keep in mind that unless things are truly independent, the point is lost. &lt;/p&gt;
&lt;p&gt;I will even take an audacious step to say that we should not use scaling as a criterion for determining microservice size. I think the other concerns will anyway guide you in the direction of achieving maximum possible scale. Again this could be controversial to some, and I am open for discussion. &lt;/p&gt;
&lt;h3 id="replaceability"&gt;&lt;span class="bold-calm"&gt;Replaceability&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;We talked about this criterion as a key advantage of microservices. Microservices allow engineering teams to build a first cut or pilot version of some functionality, and then throw it away, and replace it with something better. This promise makes a lot of sense for startups &amp;amp; even for established companies who are trying to innovate &amp;amp; stay ahead.&lt;/p&gt;
&lt;p&gt;For doing this, the size of the microservice better be small so that we developers feel that it is ok to throw it out &amp;amp; build something in its place. If we have a microservice which is large &amp;amp; holds sizeable functionality then it becomes more difficult for developers to dismantle it. We won't feel comfortable to quickly replace it. It will take a lot more effort &amp;amp; when that happens, teams tend to forgo the change. It becomes a case of not wanting to deal with the regression that the replacement might cause. So if we want replaceability, then the size of the microservice needs to be small. So this criterion pushes down from the upper limit. &lt;/p&gt;
&lt;h3 id="distributed-communication"&gt;&lt;span class="bold-calm"&gt;Distributed Communication&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;We just learned that small microservices are great for replaceability. But small does not mean good all the time. When we have small services, we invariably need to communicate between them to get work done. Distributed communication is a very hard thing to do. &lt;/p&gt;
&lt;p&gt;All of us have experienced working with distributed systems in one way or the other, and we all are aware of the &lt;a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing"&gt;fallacies of distributed computing&lt;/a&gt;. There are dozens of patterns that we can use to bring reliability in distributed communication (entire books have been written on them) but as the &lt;a href="https://martinfowler.com/articles/distributed-objects-microservices.html"&gt;first law&lt;/a&gt; states to never distribute objects if we can get away with it. &lt;/p&gt;
&lt;p&gt;So distributed communication comes with its own bag of issues (reliability &amp;amp; latency related). If we can keep this communication to a minimum then our systems will be better off. So this drives the size of microservice to be bigger - pushes up from the lower limit.  &lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="size-of-a-microservice-summary"&gt;&lt;span class="bold-green"&gt;Size of a microservice - Summary&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;We looked at a set of considerations above which act as forces governing the right size of a microservice. Whether you are trying to design/architect a new microservice or evolve one from a monolith, these considerations should be kept in mind. Obviously this is not very easy. There is no simple formula to arrive at an optimum size of a microservice. &lt;span class="small-italicized-green"&gt; (I know it feels like a letdown after reading this for such a long time. I am sorry! &lt;span class="emoji"&gt;🥺&lt;/span&gt;) &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;That said, giving a set of descriptions on these ideas is not an effective way to keep track of this information. In this section I will try to depict the above considerations into a more usable form in terms of quick reference. The idea is that once you understand the above considerations, this section could act as an easy reference for you to do the actual work of architecture.&lt;/p&gt;
&lt;p&gt;The key considerations can be treated like forces. These forces act on the upper &amp;amp; lower limit of the size of microservice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forces which push the service to be bigger, push at the lower limit not allowing it to get smaller. &lt;/li&gt;
&lt;li&gt;Forces which push the service to be smaller, push at the upper limit to not allow them to get bigger.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="figure"&gt;
&lt;img alt="Microservice sizing factors graphic" src="https://www.nacnez.com/images/ms_size/microservice_size_factors_pic.gif"/&gt;
&lt;p class="caption"&gt;Fig 4: Key factors shown as forces affecting size of a microservice &lt;/p&gt;
&lt;div class="legend"&gt;When the service tries to shrink down, the lower limit factors push to expand it. Similarly when the service tries to expand out, the upper limit factors push to shrink it down.&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;I am also tabulating these factors along with the limit they influence for easy reference.&lt;/p&gt;
&lt;div class="figure"&gt;
&lt;img alt="Microservice sizing factors table" src="https://www.nacnez.com/images/ms_size/microservice_size_factors_table.png"/&gt;
&lt;p class="caption"&gt;Fig 5: Key factors affecting size of a microservice tabulated &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Hopefully these aids will help you remember/refer to the key ideas which these thousands of words are trying to convey.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="closing-remarks"&gt;&lt;span class="bold-green"&gt;Closing remarks&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;We have come to end of this long write-up. At the end I want to leave you with some informal ideas. When deciding to build (or building) or carving out a microservice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Focus on Business capabilities &amp;amp; Service boundaries&lt;/li&gt;
&lt;li&gt;Don’t look at Lines of Code (LoC)&lt;/li&gt;
&lt;li&gt;Get a clear understanding of the user interactions involved in your service and related services.&lt;/li&gt;
&lt;li&gt;Focus on enabling agility within &amp;amp; around the engineering team.&lt;/li&gt;
&lt;li&gt;Use techniques like Bounded contexts, Aggregate design, Event storming etc.&lt;/li&gt;
&lt;li&gt;Err on the side of bigger - It is relatively easier to split it up later rather than the other way around. &lt;/li&gt;
&lt;li&gt;Be cognizant of nano/pico services. They are only useful if they are very simple utilities&lt;/li&gt;
&lt;li&gt;It is not an &lt;em&gt;"in vogue"&lt;/em&gt; thing, and you don't have to join it if you don't want to! &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That's it. We have come to the end. I have listed down all my references, so that you can go read &amp;amp; explore more. Please share your thoughts, comments, insights with me so that I can also learn from your experiences. Ciao! &lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="references-explorations"&gt;&lt;span class="bold-green"&gt;References &amp;amp; Explorations&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://martinfowler.com/articles/microservices.html"&gt;Microservices article in Martin Fowler blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.in/Microservices-Flexible-Architecture-Eberhard-Wolff/dp/0134602412"&gt;Book: “Microservices: Flexible Software Architecture” by Eberhard Wolff&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://kylegenebrown.medium.com/whats-the-right-size-for-a-microservice-bf1740370d47#"&gt;Article: "What’s the right size for a Microservice?" by Kyle Brown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ben-morris.com/how-big-is-a-microservice/"&gt;Article: "How big is a microservice?" - by Ben Morris&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.in/gp/product/B00794TAUG"&gt;Book: “Domain-Driven Design: Tackling Complexity in the Heart of Software” by Eric Evans&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.amazon.in/Domain-Driven-Design-Distilled-Vaughn-Vernon/dp/9332585369"&gt;Book: "Domain-Driven Design Distilled" by Vaughn Vernon&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ziobrando.blogspot.com/2013/11/introducing-event-storming.html"&gt;Article: Event Storming&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/hr&gt;&lt;/hr&gt;&lt;/hr&gt;&lt;/hr&gt;</content><category term="architecture"></category><category term="size"></category><category term="bounded contexts"></category><category term="microservices"></category><category term="software-engineering"></category><category term="DDD"></category><category term="domain-driven-design"></category></entry><entry><title>µservices gossip: Take a timeout!</title><link href="https://www.nacnez.com/2-%C2%B5-services-chat-timeout.html" rel="alternate"></link><published>2019-10-13T00:00:00+05:30</published><updated>2019-10-13T00:00:00+05:30</updated><author><name>Srinivas Narayanan</name></author><id>tag:www.nacnez.com,2019-10-13:/2-µ-services-chat-timeout.html</id><summary type="html">&lt;p&gt;A casual bar chat between µ services Jack and Jill about Jack's problem with Jill.&lt;/p&gt;</summary><content type="html">&lt;h4 id="act-1"&gt;Act 1&lt;/h4&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; ------------------------ The curtain opens ------------------------ &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; - Jill µ service is already sitting in the bar. The setting is typical of all bars. It is crowded with a lot of µ services having a good time with drinks and conversations. It is a chatty place. Jack µ service enters, looking haggard. - &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="A Services Bar" class="figure" src="https://www.nacnez.com/images/ms_conversation_timeout/a_service_bar.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: What a day! Shall I sit here? ... I am going to sit here. Please don't mind.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Go ahead. No problems.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Thank you. I am Jack. Who are you?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: I am Jill. Pleased to meet you in person!&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Meet you in person? What does that mean? Does that mean that we know each other?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: You talk to me all the time professionally, by calling my URI - &lt;code&gt;jill.ourcompany.io&lt;/code&gt;. Ring any bells?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Oh yeah. I know you. I send requests to that url, I mean your url all the time. Yeah, I remember.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Told you.&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; - Jill is smiling. Then Jack's demeanor changes. Looks up agitated &amp;amp; angry - &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: You gave me so much &lt;strong&gt;PAIN&lt;/strong&gt; last week. Why did you do that?&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; - Jill looks at Jack shocked for a moment, but calms herself down - &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: What did I do?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Oh! You don't remember last wednesday. Oh boy! I remember it all.&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; - A look of understanding comes on Jill's face - &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Ah! I do remember. It was a bad day. My development guys were all looking at my problem...&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; - Jack lifts his hand and interrupts Jill - &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: &lt;strong&gt;No, no, no!&lt;/strong&gt; It was a &lt;strong&gt;BAD&lt;/strong&gt; day for me. I got &lt;strong&gt;sc***ed&lt;/strong&gt; because of you. It is all because of you.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Hold on. Let us take it slow. Here, have a drink.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: &lt;strong&gt;Don't patronize me&lt;/strong&gt;. You did this to me.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: What really happened? You need to give me details so that I can understand. Calm down and have this.&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; - Jill picks up the &lt;code&gt;CPU credits&lt;/code&gt; from the counter and hands it to Jack and he takes a swig. Jack looks a bit satiated - &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Okay. This is what happened. I called you to get the answers I need from you to do my job as usual. I waited for an answer but it never came. And I kept waiting. Then more people asked for the information and I called you again. And you just did not respond. I got all stuck up - all blocked threads; all my servers froze up. I couldn't serve any of my customers. Everyone was shouting &amp;amp; pinging me again &amp;amp; again but, I just couldn't do anything. I lost face because of you.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Ok. Let us talk through this. We are both µ services. We take care of different aspects of the business domain - my developers call it &lt;a href="https://martinfowler.com/bliki/BoundedContext.html"&gt;bounded contexts&lt;/a&gt;. We work together to ensure that our customer needs are met. Your customers are my customers too. For a given usecase, many times, we have to talk to each other and get things done. And we do that all the time and mostly it is successful.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Yeah, I know that. I am not &lt;strong&gt;d**b&lt;/strong&gt;. But on that day, you....&lt;/p&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; - Jill interrupts Jack - &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Hold on Jack. Let me finish. We both want the same thing &amp;amp; you need to understand that. But given the nature of the world we live in, it is possible that one of us doesn't work as well at times. Things go wrong with the Infra guys sometimes. Or sometimes our developers make a mistake. And sometimes the Network guy acts up - rare - but that does happen. We are a &lt;a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing"&gt;distributed system&lt;/a&gt;. We have to live with the problems that come with it.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Cascading Failures" class="figure" src="https://www.nacnez.com/images/ms_conversation_timeout/dominos.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Yeah, yeah. I understand all that. But I really don't want go down when you go down. I don't like this &lt;span class="bold-angry"&gt; CASCADING of failures &lt;/span&gt;. There are many things that I can do to help my customers even when you are down. But since you bring me down with you, I can't serve anyone. I &lt;strong&gt;don't&lt;/strong&gt; like it.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: I understand that Jack. I appreciate you wanting to be available for our customers. Please believe me. But as I said, things go wrong with us at times. Last week, I heard your DB guy was acting up and you couldn't help your customers. &lt;em&gt;Pitcher µ&lt;/em&gt; was complaining about it to me.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Yeah, that did happen. I know it happens to all of us. But I don't want to feel helpless like this.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Let us dig deeper Jack. How do you call me to get your answers?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: I call you through your REST endpoint. I make a call with the right parameters and you return back a JSON response almost immediately. That is the way I like it. But that time everything went wrong.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Timeouts" class="figure" src="https://www.nacnez.com/images/ms_conversation_timeout/timeout.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: I got what you are doing now. By the way, do you use &lt;span class="bold-calm"&gt; TIMEOUTS &lt;/span&gt; on your side? I mean on your calls to me as a client.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: What timeouts? I don't follow you.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Ok. Timeout is the concept of time boxing an operation so that, if things don't work out within that time, you give up and move on to something else. This is employed in many places. Not just in service to service requests, but when getting any resource that is used by µ services like us. We could use timeouts for acquiring a lock, connecting to a database or file system. In all such actions, timeout is good idea.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jack µ&lt;/span&gt;: I don't follow that fully. Can you explain it a bit more?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Sure. Let me take an example of what I do. Whenever I try to connect to a database, I try it for a period of 6 seconds. If something is wrong - I mean the DB could be having some issues or the network could be acting up, I give up on that task temporarily and throw an error for everybody to see and move on to other things. I might try it again, but I don't keep hoping and waiting forever for things to happen in the first call. Am I making sense?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-angry"&gt;Jack µ&lt;/span&gt;: Kind off.... But... But if you give up, then you can't serve the customer needs. I mean you don't have the data to serve the request. Then, what is the point?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: You are right. For &lt;em&gt;that&lt;/em&gt; request, I can't serve the customer for sure. But I also don't get bogged down by a slow or failed resource or dependency. I can drop that request and serve other requests. This way, I don't have a set of &lt;span class="bold-angry"&gt; blocked threads &lt;/span&gt; and won't become completely unresponsive. Isn't that better?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jack µ&lt;/span&gt;: Yeah. It sort of makes sense at a high level. Not sure, how it applies to me though.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: You said you call my REST endpoint. That is a http call and you must be using some kind of http client. Almost all good http client libraries whether it is in &lt;a href="https://realpython.com/python-requests/#timeouts"&gt;Python&lt;/a&gt;, &lt;a href="https://github.com/excon/excon#options"&gt;Ruby&lt;/a&gt;, &lt;a href="https://www.baeldung.com/httpclient-timeout"&gt;Java&lt;/a&gt; or any other language, will provide a way to configure timeouts. So go ahead and configure them with some sane values and you are done.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jack µ&lt;/span&gt;: Wow! That is interesting. So what kind of timeouts are involved in http calls?&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Typically there are two timeouts that are configured. One is the connection timeout - the time taken for establishing the tcp connection. The other is a read timeout - which is time waiting for data to be received during a read. All these libraries provide the ability to configure both these values. Once you configure them to appropriate values as applicable to you, you are done.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jack µ&lt;/span&gt;: That sounds pretty neat. So you are saying that once I configure myself with these timeouts for my interactions with you, I will be hale, healthy and happy!&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Sure. Doing this will be a great step towards your own stability and avoiding &lt;strong&gt;Cascading Failures&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jack µ&lt;/span&gt;: Okay! This is good. I am finishing this drink and going to talk to my Dev folks right after. I am going to be the stablest µ service in the world. Cheers!!&lt;/p&gt;
&lt;p&gt;&lt;span class="bold-calm"&gt;Jill µ&lt;/span&gt;: Cheers!! Have fun buddy! Have a timeout!&lt;/p&gt;
&lt;h2 id="music-grows-louder-and-jack-and-jill-go-up-to-the-dance-floor"&gt;&lt;span class="small-italicized-green"&gt; Music grows louder and Jack and Jill go up to the dance floor. &lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class="small-italicized-green"&gt; ------------------------ The curtain falls ------------------------ &lt;/span&gt;&lt;/p&gt;</content><category term="architecture"></category><category term="resilience"></category><category term="microservices"></category><category term="play"></category><category term="bounded contexts"></category></entry><entry><title>Caching in Microservices</title><link href="https://www.nacnez.com/caching-in-microservices.html" rel="alternate"></link><published>2019-09-15T00:00:00+05:30</published><updated>2019-09-15T00:00:00+05:30</updated><author><name>Srinivas Narayanan</name></author><id>tag:www.nacnez.com,2019-09-15:/caching-in-microservices.html</id><summary type="html">&lt;p&gt;A overview of caching in the context of microservices&lt;/p&gt;</summary><content type="html">&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;TL;DR&lt;/p&gt;
&lt;p&gt;Caching in microservices can help with improving performance and scaling if used wisely. Opt for service level domain aggregate caches and use mashed up object caching on client services only when you are trying to speed-up/avoid local processing on remote data. Don't use blackboard caches and remember cache cannot be a source of truth or a permanent data store.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="admonition note"&gt;
&lt;p class="admonition-title"&gt;Origin Note&lt;/p&gt;
&lt;p&gt;This article is based on a talk I gave at an event hosted by &lt;a href="https://everest.engineering/#events"&gt;Everest Engineering&lt;/a&gt;. The article serves both as a independent reference on the topic for anybody and a refresher for people who attended the talk.&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id="why-caching-in-microservices"&gt;Why caching in Microservices&lt;/h2&gt;
&lt;p&gt;Microservices offer us a lot of advantages but they are not a silver bullet. Every architecture tries to satisfy the &lt;strong&gt;“ities”&lt;/strong&gt; . This architecture style is no different. It is very promising but it is not without its trade-offs.&lt;/p&gt;
&lt;p&gt;Everyone has heard of caching. It is prevalent in our world of computers and software at multiple levels. From the CPU level L1/L2 cache, to in-memory caches in our monoliths, all of us would have seen caching in some place or the other. Why is it used? There are two desirable characteristics for any user feature:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Respond to the user very fast - performance.&lt;/li&gt;
&lt;li&gt;Respond to a lot of users - scale.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And caching can help with both.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
But do microservices need them? Microservices already offer a lot of good qualities to our systems - like independent scaling, independent data storage for better performance etc. . So should we care about caching. Also caching is not the easiest thing. You might have read about the saying in Martin Fowler's bliki -  &lt;a href="https://martinfowler.com/bliki/TwoHardThings.html"&gt;Two Hard Things&lt;/a&gt;:&lt;/p&gt;
&lt;div class="admonition danger"&gt;
&lt;p&gt;&lt;strong&gt;There are only two hard things in Computer Science: cache invalidation and naming things&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To answer this let us dig deeper to identify challenges which microservices introduces.&lt;/p&gt;
&lt;h4 id="use-case-viewingediting-an-online-document"&gt;Use case - Viewing/Editing an online document&lt;/h4&gt;
&lt;p&gt;&lt;img alt="Editing online document" src="https://www.nacnez.com/images/caching_in_ms/usecase1.png"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
The use case is pretty common. So let us look at potential architecture for making this work. For showing a single document to the end user there are 5 - 6 services involved if we adopt microservices architecture.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Editing online document - Architecture" src="https://www.nacnez.com/images/caching_in_ms/usecase1-archi.png"&gt;&lt;br&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;The individual components are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Document service - This one serves the original document.&lt;/li&gt;
&lt;li&gt;Comments service - This one provides the various comments created on top of the document by different users.&lt;/li&gt;
&lt;li&gt;Authentication service - This is a system service which ensures that the call to the document service is from an authenticated user. This could be API gateway but I am representing it as a service so that it is clear that it is another layer/system involved in the interaction.&lt;/li&gt;
&lt;li&gt;Authorisation service - It checks if the user can see/edit the document - Action level authorisation.&lt;/li&gt;
&lt;li&gt;Tenant service - This ensures that the document requested belongs to the same tenant as the user - Data level authorisation&lt;/li&gt;
&lt;li&gt;User Document service - The Orchestrator. This talks to the underlying services and mashes up the final information and sends to the user.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Given the above architecture, let us think about performance. Generally a single request made by the user is expected to respond within 300-500 ms. The idea is that if the first byte comes through fast then, there is some time for the browser to visually display the content along with any client side processing it has to do within 2-3 secs.&lt;/p&gt;
&lt;p&gt;In the above microservices architecture instead of one service (monolith) returning within that time, all these 5 services should work together to respond within the same time. For simplicity, if we are thinking of splitting it up equally we are talking about 50-80 ms per service. That can be pretty tight. If the page is not ready for end user consumption in 2 - 3 seconds, the user will move to a different document editor provider.&lt;/p&gt;
&lt;p&gt;Microservices offer a lot of good. But in this context where we need great performance, the need to talk to multiple services to respond to one use case can mean a very slow and painful experience for the end user. Not good. We need to do something. &lt;em&gt;What can we do which will help us improve performance and scale?&lt;/em&gt; &lt;strong&gt;Caching!!&lt;/strong&gt; Applying caching to microservices allows us to hit our required goals. That does not mean that we apply caching to anything &amp;amp; everything. There are things to consider, things to manage.&lt;/p&gt;
&lt;p&gt;Now that we have established why caching is useful, let us get into more detail about caching. Let us start with what you would want to cache.&lt;/p&gt;
&lt;h2 id="what-to-cache"&gt;What to cache&lt;/h2&gt;
&lt;p&gt;A general cache acts like a map or hash or dict. Pick your term based on your language of choice. Any object is added to the cache by identifying it with a key. A cache generally does not care what value it caches. You can then retrieve the value using the key. So we could cache any kind of object in a cache. But what should we cache?&lt;/p&gt;
&lt;div class="admonition attention"&gt;
&lt;p class="admonition-title"&gt;Out of scope&lt;/p&gt;
&lt;p&gt;Before we go deeper, I am not covering the entire topic of http caching. While http caching is useful in the context of microservices they are not really specific to them. It is applicable more generally.&lt;/p&gt;
&lt;/div&gt;
&lt;h4 id="domain-objectsaggregates"&gt;Domain objects/aggregates&lt;/h4&gt;
&lt;p&gt;In the world of services (I will interchangeably use service and microservice because I believe microservice is just a SOA service done right), one of the primary things you should consider caching are domain aggregates or objects. Any given microservice generally deals with one primary domain aggregate or object (may be two if it makes sense). In the example we talked about earlier, we had an comment service whose primary domain object is comment. Similarly document could be the one for document service. Caching the primary domain aggregate/object means that all relevant information required by the client can be easily served up quicky without looking at multiple places - especially the database. The actual response could be a subset of the data, but caching the aggregate allows us to adapt &amp;amp; support many use cases. We know databases and associated disk reads can be the cause of big performance delays. By caching domain aggregates we make it much easier for the service to serve its clients. There are still things to consider here. We will discuss about it down the line.&lt;/p&gt;
&lt;h4 id="configurations"&gt;Configurations&lt;/h4&gt;
&lt;p&gt;Another thing we look at caching is configurations of a service. This one is fairly common even in the monolith world. Configurations generally don’t change much and are used in different parts of the app - hence they are a great candidate for caching.&lt;/p&gt;
&lt;h4 id="mashed-up-objects-with-processingcalculations"&gt;Mashed up objects with processing/calculations&lt;/h4&gt;
&lt;p&gt;The above two cases are straight-forward. Next thing to consider for caching is mashed up objects. This is typically employed by an orchestration service acting as client to other services, and it involves merging in responses from these services, doing some calculations or processing on top of them and caching the result. Again referring to the use case above, the user document service might take the document(s) from the document service and merge the applicable comments from comments service and cache these rich documents on its side. This means that you not only avoid round trips to other services but also don’t need to do the additional processing to match, merge and position them. This means better performance and also lesser load (hence better scale) for all the services involved. There are trade-offs involved here too and we will get to them.&lt;/p&gt;
&lt;p&gt;As a general advice, I would say that you should cache everything &lt;strong&gt;BUT&lt;/strong&gt; only if you can.&lt;/p&gt;
&lt;h2 id="where-to-cache"&gt;Where to cache&lt;/h2&gt;
&lt;p&gt;Now that we know what to cache, let us talk about where to cache.&lt;/p&gt;
&lt;h4 id="in-service-memory"&gt;In service memory&lt;/h4&gt;
&lt;p&gt;Within a service, we could just use an in process / in memory cache and improve performance with great ease. This works, but is applicable for a very limited set of use cases. One example is static configuration information. This is not very large in size can be stored in a in-memory, in-process cache. Given that any service worth its salt will be setup as a cluster in a production setup, we have a replicated cache in each of the service nodes. This cache will be the fastest of all since it is not just in memory, it is in same process as the service.&lt;/p&gt;
&lt;p&gt;The above approach allows us to get started, but falls apart soon. When we want to cache domain aggregates/objects, a clustered service will find it very difficult to keep changes in sync across the memories of multiple service nodes. Also, once you go down the path of caching and get the taste of performance gains, you will plan to cache a more in memory. This means that the cache is competing for memory with the actual service procesing requests. This can lead to reduction of service scale. It is time to move out of service memory.&lt;/p&gt;
&lt;h4 id="out-of-service-memory-standalone"&gt;Out of service memory - Standalone&lt;/h4&gt;
&lt;p&gt;The first obvious choice here is to have a standalone caching solution which can be reached by different service nodes for both reading and writing data. This is obviously going to be slower than the in-process cache but it will still be faster than going to the database and doing disk reads. Also given that it is separated from individual service nodes it removes the overhead created by cache storage on the individual nodes. Typical solutions used here are Redis, Memcached etc.&lt;/p&gt;
&lt;h4 id="out-of-service-memory-distributed"&gt;Out of service memory - Distributed&lt;/h4&gt;
&lt;p&gt;When we want scale these even further, we get into distributed caching and in-memory data grids. These solutions allow for multiple nodes holding a large amount of data in memory for faster response and higher scale. It is not uncommon to have a 100 node cluster of in-memory data grid machines which are hosting terabytes of data in memory by employing partitioning of data across different nodes.&lt;/p&gt;
&lt;p&gt;Each of these individual solutions provide a lot of different features but that is not our focus.&lt;/p&gt;
&lt;p&gt;What we have covered now is a broad base of locations where data could be cached. Each location of storage has pros and cons and are suited depending on our needs.&lt;/p&gt;
&lt;h2 id="when-to-cache"&gt;When to cache&lt;/h2&gt;
&lt;p&gt;We now know what to cache and where to cache it. Now let us discuss when we would cache any data.&lt;/p&gt;
&lt;h4 id="on-demand"&gt;On Demand&lt;/h4&gt;
&lt;p&gt;One approach to populate the cache with data is when it is required. When a particular piece of data is requested and the cache does not have the same, then the data is picked up from the source, the cache seeded with the same and then returned back to the requester. This is the &lt;em&gt;On Demand&lt;/em&gt; mode of populating a cache. This mode can work in most scenarios but has a couple of drawbacks. The first request which populates the cache will be very slow and leads to a bad experience to that end user(s). The other one that if there are multiple service nodes which request for the same entry then it could cause database contention.&lt;/p&gt;
&lt;h4 id="pre-loading"&gt;Pre-loading&lt;/h4&gt;
&lt;p&gt;The other approach to when to cache is to pre-load data upfront. As part of the service initialisation process, the cache was seeded with required data. This means that there is a huge load on the data store during start up and hence a potential delay in start up. But once the loading is complete, the cache is primed and end user experience is great - no more delays even for the first user. And if you cache most of the relevant data, we might even survive a db outage! One problem with this is that, we don’t know what to cache if we are not planning to cache everything.&lt;/p&gt;
&lt;h2 id="how-to-cache-patterns"&gt;How to cache - Patterns&lt;/h2&gt;
&lt;p&gt;Let us get into details of how caching can be implemented within microservices. There are some well known patterns for reading and writing to cache. These have their pros and cons as well. Also they are not mutually exclusive in any way. They generally work together to solve problems. Let us go through them one by one.&lt;/p&gt;
&lt;h4 id="cache-aside"&gt;Cache aside&lt;/h4&gt;
&lt;p&gt;&lt;img alt="Cache aside pattern" src="https://www.nacnez.com/images/caching_in_ms/cache_aside.png"&gt;&lt;/p&gt;
&lt;p&gt;The first one is the &lt;em&gt;Cache aside&lt;/em&gt; pattern. This is the most common pattern and used extensively. The idea of the pattern is to treat cache as a different store similar to the database. A service would read and write to the database and the cache as an aside. The control of what and when data are written into or read from the cache lies with the service itself. This pattern is great for read heavy workloads. Also we could write the service in such a way that during a failure in cache setup - when we use standalone/grid mode - the service can still keep serving from db. Of course this can’t be sustained for long given the cache setup is to support scale, but the option is there. The approach for when writes happen depends on us. Writing to database is the first thing the service will do - almost always. What happens to the cached entry is subject to developers choice - the patterns leaves this open to us. One thing to do is to just remove or invalidate the entry from the cache. There are others options available.&lt;/p&gt;
&lt;p&gt;I prefer this approach because as a business service writer I have lot more control with this approach. Hence I have used it a lot as well.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
Sometimes we really don’t want so much control. Rather we want convenience and ease of use. The following patterns afford this one way or other and the unifying aspect of these patterns is that the caching library or system acts as the facade and controls how data is written/read to/from the underlying source data store.&lt;/p&gt;
&lt;h4 id="read-through"&gt;Read through&lt;/h4&gt;
&lt;p&gt;&lt;img alt="Read through pattern" src="https://www.nacnez.com/images/caching_in_ms/read_through.png"&gt;&lt;/p&gt;
&lt;p&gt;The first one among them is the &lt;em&gt;Read-Through&lt;/em&gt; pattern. Here the cache, when requested for a entry and not finding it, will initiate a call to the underlying store to read the data. It will then cache it and return the data to requester. The key thing to note here is, the cache is the one orchestrating the action. This is different from how cache aside pattern works where the control is with the service code. Also Read through pattern follows lazy or on-demand loading and hence has the same caveats. We must also remember that in this pattern the data structure cached must match with the structure stored in the underlying store.&lt;/p&gt;
&lt;p&gt;Even in Cache aside, we could follow a similar technique of lazy loading when writes happen (i.e writes just invalidates the corresponding entry in cache if it exists) if the applicable caveats work for you.&lt;/p&gt;
&lt;h4 id="write-through"&gt;Write Through&lt;/h4&gt;
&lt;p&gt;The &lt;em&gt;Write Through&lt;/em&gt; pattern is about writing data. This is similar to Read-Through - the cache system sits in between the service code and database.  With this approach when changes are made to the cached entity, the service writes into the cache and that in turn writes into the database. Both writes need to be completed before completion of request. This adds a bit of an overhead to the write operation but when combined with Read Through pattern it gives a lot of benefits. The write through pattern ensures that entries in the cache are not out-dated or stale. So we have consistent data available at very high speeds for reads. This is great for a cache.&lt;/p&gt;
&lt;p&gt;Even with the Cache Aside pattern, we generally employ a similar approach to read through and write through. The difference is of course that the service controls the entire interaction rather the cache system.&lt;/p&gt;
&lt;h4 id="write-around"&gt;Write-Around&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Write-Around&lt;/em&gt; Cache is a slightly different from the older one. Here the write happens only to the database and the cache is updated only during a read through. There are some advantages - writes are faster but at the same time they are durable (since db is written). But reads could miss cache or even return stale data. This approach is great for write heavy workloads where reads are much less - e.g. is real time logs.&lt;/p&gt;
&lt;h4 id="write-back-or-write-behind"&gt;Write-Back or Write-Behind&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Write-Back or Write-Behind&lt;/em&gt; Cache is another variation. Here the service writes to the cache and returns. The cache will write to the DB behind the scenes with some potential delay. Of course writes are super-fast but there are chances of missed writes too. Combined with read through, you get a good cache times for most mixed workloads - you always have the recently updated and accessed data. Also one can argue that it is resilient to db failures - (but how long? - keep that in mind). Another thing possible is that multiple writes to the same object could be coalesced into one write to the db.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;
As I said earlier these are general patterns which have trade-offs. And they are always combined. In my own opinion, treating a cache as a data source is rarely a good idea. Unless you have throwaway data or what you holding is always derived reconstructable data. If not stick to the more durable write patterns always.&lt;/p&gt;
&lt;h2 id="how-long-to-cache-invalidation"&gt;How Long to Cache - Invalidation&lt;/h2&gt;
&lt;p&gt;We are now embarking on the one of toughest problems in computer science! (referred already). In my experience this is a true statement.&lt;/p&gt;
&lt;p&gt;Any cache we create is an alternate store of data and cache is not the source. That means it is bound to go out of sync with the source. This is called as going &lt;em&gt;stale&lt;/em&gt;. Unlike stale food, stale data from cache is not always bad. That said we can’t keep having stale data and serve our clients with the same. How long we can use stale data depends on your business scenario.&lt;/p&gt;
&lt;p&gt;News sites with stories could show some stale data - slightly older news - may be few hours. But a stock ticker like app which enables users to trade cannot real work with stale data! So it depends.&lt;/p&gt;
&lt;p&gt;Let us figure out how to get out of this stale state.&lt;/p&gt;
&lt;h4 id="expiry"&gt;Expiry&lt;/h4&gt;
&lt;p&gt;One of the ways to deal with staleness is expiry. Depending on the data you are trying to cache, you generally know how long the data can remain fresh and live. If so, we can set the data to expire. This is generally called Time To Live or ttl. Most caching frameworks will drop the data once it passes ttl - either actively or passively. A request for this expired data will result in a cache miss. The next step depends on the caching patterns you use. Many caching frameworks allow us to set this expiry at the bucket level (all new stories) as well as individual item (a particular new story) level - we can use any as required.&lt;/p&gt;
&lt;h4 id="service-based"&gt;Service based&lt;/h4&gt;
&lt;p&gt;While expiration is a reasonable way of handling invalidation, we could handle it more actively. When we use caching within a service boundary, a service has control over the data which it is caching and hence can actively manage the invalidation of stale data. For example when more comments are added to a document, the change happens through the service and it can actively manage the cache invalidation. This is one of the reasons I prefer the service based approach.&lt;/p&gt;
&lt;h4 id="events-based"&gt;Events based&lt;/h4&gt;
&lt;p&gt;Another way invalidation can be achieved is through events. This technique is especially applicable when orchestration service clients cache mashed up data. When the object owner service finds that data has changed, it sends out an event to an event bus or MOM. This is consumed by the orchestration service to take appropriate action.&lt;/p&gt;
&lt;h2 id="two-more-concepts-on-caching"&gt;Two more concepts on Caching&lt;/h2&gt;
&lt;h4 id="measurements"&gt;Measurements&lt;/h4&gt;
&lt;p&gt;Anything we do, we should measure. There is a saying in Tamil&lt;/p&gt;
&lt;div class="admonition info"&gt;
&lt;p&gt;&lt;strong&gt;ஆற்றில் போட்டாலும் அளந்து போடு&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Even when you are just going to throw something into the river you should measure and throw it.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;One of the critical measurements for any caching setup is the cache hit ratio. Every one understands what a cache hit is - when a cache access succeeds. And a cache miss when you miss. So cache hit ratio is:&lt;/p&gt;
&lt;div class="admonition tip"&gt;
&lt;p&gt;&lt;strong&gt;Cache Hit Ratio&lt;/strong&gt; = &lt;em&gt;Cache Hit&lt;/em&gt; &lt;strong&gt;/&lt;/strong&gt; (&lt;em&gt;Cache Hit&lt;/em&gt; &lt;strong&gt;+&lt;/strong&gt; &lt;em&gt;Cache Miss&lt;/em&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For caching to be considered effective, the data cached must have a good cache hit ratio. If you have a low cache hit ratio then you are surely doing something wrong. Either you are using the wrong cache patterns or you are caching the wrong data. Any changes you want to do related to caching (change methods/techniques or something else) must keep the cache hit ratio in mind. Any change reducing the cache hit ratio is a bad idea.&lt;/p&gt;
&lt;h4 id="eviction"&gt;Eviction&lt;/h4&gt;
&lt;p&gt;We talked about expiry a lot. There is another concept which people consider closely related to it - Eviction. Actually eviction is very different from Expiry. It has more connection to the &lt;em&gt;cache hit ratio&lt;/em&gt; and &lt;em&gt;what to cache&lt;/em&gt; question. Both expiry and eviction deal with removal of entries, but their causes and purposes are completely different.&lt;/p&gt;
&lt;p&gt;Cache eviction comes into play because memory is a finite resource - for the most part that is. While I would love to cache the entire database it is just not economical to do it. So once the amount we cache exceeds a number limit or memory limit, any addition of entry means some other entry needs to be removed out of memory. This process is called eviction. Eviction is generally done based on some algorithmic strategy. Different caching frameworks provide many different algorithms. The most common ones are LRU, LFU, FIFO.&lt;/p&gt;
&lt;p&gt;LRU is the most common is generally considered a reasonable default. It is considered a close proxy to the most optimal caching algorithm. The specific reason is due to Locality of reference. This is easily explained in the context of caching at the CPU level where the recently used data or instruction is repeatedly requested by the CPU. This is called Temporal Locality. The same phenomenon applies to the real world usage of cached data too. We can understand this intuitively. For example most times when data is created it is immediately accessed. Also when real users surf through data like products they tend to return to see the same products again and again. Another example is generally items like dresses or vehicles come into trend in time cycles (or may be because there is a big sale going on). Temporal locality makes sense. In my experience of using caches, I have never needed to change the eviction algorithm to something else. Nor have I heard of any real life usage of any other algorithm - that is anecdotal for sure but I am pretty convinced. &lt;/p&gt;
&lt;p&gt;Changing a caching algorithm to something else is mostly a configuration change. The more important thing is, when we make such a change, we need to measure cache hit ratios and average response times and see how they are affected.&lt;/p&gt;
&lt;h2 id="conclusion-summary-of-opinions"&gt;Conclusion - Summary of Opinions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Preferred Approach - Service Caching&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I prefer to use service managed caches as an approach to caching. Given that service owns the data, as a service developer I have a much clearer understanding of how and when data changes and hence I can make decisions more easily. With this approach clients are unaware of what is happening and hence they are not affected by any changes to mode/mechanism of caching. I can keep tweaking the implementation as long as I satisfy the performance SLA. I can keep improving performance or scale without having clients to have to change anything. A service can internally use in process caching or stand alone caching to begin with and then move to an IMDG as it needs more scale. All good right!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;But you sometimes need - Orchestrator/Client side caching&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Not really. Service level caching does not solve all scenarios. Clients sometimes want even better response times than what service level caching can provide. Network latency could be one reason. I generally don’t really think it is a great argument since once you want to scale the client you would need an out of process cache and then the network latency is back. But that is not the only reason. There are situations where client services mash up data from multiple services and do some processing on top and use it. In such cases it might be required for that service to cache the outcome of the processing to quickly serve clients. I have done the same in one of previous situations because it was needed to meet the SLA for the service - to keep real users happy. Though this approach is sometimes required, we must understand that it is a complex thing to manage. We need to build in checks which will ensure that this cache data still ties back to original data source services - potentially an event based mechasim.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; Never ever Shared Caches&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One of ways which I have seen caching being used is like a blackboard where some service can write something and another service can read the same. This is possible to do but I am not in favour of it. This feels very much like multiple services using the same underlying database - a global namespace. Any change cannot be done in an isolated manner and every service can touch or be touched by all changes happening on the shared cache. So beware of it. I am not saying that this cannot be done. It feels more dirty and complicated and hence can turn ugly if we are not very careful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; And not really a replacement to DB&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;And last piece of advice or opinion. Never treat your cache as your database even if it super reliable with great clustering features. Some IMDG vendors say that it is possible. In my experience that is not what they are good at and hence they don’t work well as good persistent stores.&lt;/p&gt;
&lt;p&gt;I am done. Share your thoughts or questions through comments below.&lt;/p&gt;</content><category term="microservices"></category><category term="caching"></category><category term="talk"></category></entry></feed>